{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dcddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader    \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d438d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2469\n",
      "118\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "\n",
    "data_dir = \"/home/bhavik/neonLabs-ai/personal/farmbot/deep_learning/dataset\"\n",
    "\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "train_imgs = os.listdir(train_dir + '/images')\n",
    "test_imgs = os.listdir(test_dir + '/images')\n",
    "valid_imgs = os.listdir(valid_dir + '/images')\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "valid_data = []\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "valid_labels = []\n",
    "\n",
    "print(len(os.listdir(train_dir + '/images')))\n",
    "print(len(os.listdir(test_dir + '/images')))\n",
    "print(len(os.listdir(valid_dir + '/images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = glob.glob('/home/bhavik/neonLabs-ai/personal/farmbot/deep_learning/agri_data/data/*.jpeg')\n",
    "train_labels = [i.rsplit('.',maxsplit=1)[0]+'.txt' for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6078f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load dataset and transform into tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65bbb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs, labels, mode= \"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.imgs[index]\n",
    "        label_boxs = self.labels[index]\n",
    "        img = Image.open(train_dir + img_name ).resize((224,224,3))\n",
    "\n",
    "        if self.mode == \"train\" or self.mode == \"val\":\n",
    "            \n",
    "            bboxs = []\n",
    "            i = 0\n",
    "            \n",
    "            for i in range(len(label_boxs)):\n",
    "                for j in range(len(label_boxs[i])//5):\n",
    "                    bboxs.append(label_boxs[i][j])\n",
    "            \n",
    "            for l in label_boxs:\n",
    "                bboxs.append(l[i:i+4])\n",
    "                i +=4\n",
    "\n",
    "            bboxs = torch.tensor(bboxs, dtype=torch.float32)\n",
    "            \n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img, bboxs\n",
    "\n",
    "        elif self.mode == \"test\":\n",
    "            img = self.transforms(img)\n",
    "\n",
    "    def __getlen__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7774c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load labels \n",
    "\n",
    "train_labels = load_labels(train_dir)\n",
    "test_labels = load_labels(test_dir)\n",
    "valid_labels = load_labels(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b644b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and transform dataset into tensors\n",
    "\n",
    "train_dataset = WeedDataset(train_imgs, train_labels)\n",
    "test_dataset = WeedDataset(test_imgs, test_labels, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using dataLoaders\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, labels in train_data_loader:\n",
    "    plt.imshow(imgs[1])\n",
    "    print(labels[1])\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Research on neural network architecture using torch for embedded device, \n",
    "# optimised for detection speed and accuracy\n",
    "\n",
    "# \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240ec953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training pipeline using net class\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59a9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2693d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(test_data, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "torch.save(net.state_dict(), \"/home/bhavik/neonLabs-ai/personal/farmbot/deep_learning/saved_models\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608fa3a",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "#### Architecture of CNN for bi-classification\n",
    "\n",
    "**Test performance**\n",
    " \n",
    "* AlexNet\n",
    "* GoogleNet\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cv-nd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e474d685ef72df78f470957d5524daaf68c69ee7130b8adbe92a3f75712c9e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
